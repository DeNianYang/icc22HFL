{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "collectible-enterprise",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import random\n",
    "from random import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "congressional-support",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_ints(mean, std, size):\n",
    "    randomNums = np.random.normal(loc=mean, scale=std, size=size)\n",
    "    randomInts = np.round(randomNums)\n",
    "    randomInts = list(randomInts)\n",
    "    f_randomInts = [int(x) if x>=2 else 1 for x in randomInts]\n",
    "    return f_randomInts\n",
    "\n",
    "def rand_data (mean, std, size):\n",
    "    randomNums = np.random.normal(loc=mean, scale=std, size=size)\n",
    "    randomInts = np.round(randomNums)\n",
    "    randomInts = list(randomInts)\n",
    "    lower = int(mean-(std*2))\n",
    "    d_randomInts = [int(x) if x>=lower else lower for x in randomInts]\n",
    "    return d_randomInts\n",
    "\n",
    "def rand_trust(mean, std, size):\n",
    "    randomNums = np.random.normal(loc=mean, scale=std, size=size)\n",
    "    randomNums = list(randomNums)\n",
    "    t_random = []\n",
    "    for x in randomNums:\n",
    "        \n",
    "        if x >=0.99:\n",
    "            t_random.append(0.97)\n",
    "        elif x < (mean-std):\n",
    "            t_random.append(mean-std)\n",
    "        else:\n",
    "            t_random.append(x)\n",
    "    \n",
    "    return t_random\n",
    "\n",
    "\n",
    "\n",
    "#-----------generate SIoT node and communication topology----------------\n",
    "def generated_node(size, degree, cmp_mean, cmp_std, \n",
    "                   cmu_mean, cmu_std, \n",
    "                   lab, iid, primary, num_data, d_std_ratio, l_std_ratio):\n",
    "    \n",
    "#-----------generate SIoT node with computation cost and data -------------\n",
    "    SIoT_nodes = []\n",
    "    # generate the computation cost\n",
    "    computation_costs = rand_ints(cmp_mean, cmp_std, size)\n",
    "    data_distribution = rand_data(num_data, num_data*d_std_ratio, size)\n",
    "    print(\"total data:\",sum(data_distribution))\n",
    "#     print(data_distribution)\n",
    "    # generate the node with the computation cost and the data distribution\n",
    "    #iid setting\n",
    "    if iid:\n",
    "        print (\"Data distribution is IID.\")\n",
    "        for x, y in enumerate(computation_costs):\n",
    "        \n",
    "            n_data = data_distribution[x]\n",
    "            l_std = l_std_ratio*n_data/lab\n",
    "        \n",
    "            # generate the label distribution\n",
    "            label_num = rand_ints(n_data/lab, l_std, lab)\n",
    "            \n",
    "            #combine the computation cost and data distribution\n",
    "            node_info = (x, {\"cmp\":y,\n",
    "                            \"total_data\": sum(label_num),\n",
    "                            \"d_data\": label_num,\n",
    "                            \"p_level\": 0,      # the privacy requirment \n",
    "                            \"pri_n\": -1})    # the node that let it has this p_level \n",
    "            SIoT_nodes.append(node_info)\n",
    "    \n",
    "    else:\n",
    "        print (\"Data distribution is non-IID.\")\n",
    "        for x, y in enumerate(computation_costs):\n",
    "            \n",
    "            n_data = data_distribution[x]\n",
    "    \n",
    "            i = randint(0, lab-1)\n",
    "            label_num = rand_ints(n_data*(1-primary)/9, l_std_ratio*n_data*(1-primary)/9, lab)\n",
    "            label_num[i] = int (n_data*primary)\n",
    "            node_info = (x, {\"cmp\":y,\n",
    "                            \"total_data\": sum(label_num),\n",
    "                            \"d_data\": label_num,\n",
    "                            \"p_level\": 0,      # the privacy requirment \n",
    "                            \"pri_n\": -1})    # the node that let it has this p_level \n",
    "            SIoT_nodes.append(node_info)\n",
    "\n",
    "#-----------generate SIoT edge with communication cost -------------    \n",
    "    \n",
    "    edges = []\n",
    "    # generate edges\n",
    "    for x in range(num_node):\n",
    "        e = []\n",
    "        while(len(e)< node_degree):\n",
    "            i = randint(0, num_node-1)\n",
    "            if (i not in e and i!= x):\n",
    "                e.append(i)\n",
    "        for j in e:\n",
    "            edges.append((x,j))\n",
    "\n",
    "    # remove duplicate edges  EX. (a,b), (b,a)  \n",
    "    for e in edges:\n",
    "        if ((e[1], e[0]) in edges):\n",
    "            edges.remove((e[1], e[0]))\n",
    "\n",
    "    #generate the communication cost\n",
    "    communication_costs = rand_ints(cmu_mean, cmu_std, len(edges))\n",
    "\n",
    "    #combine the edges and the communication cost\n",
    "    edges_cmu = [(edges[x][0], edges[x][1], {\"cmu\":y}) for x, y in enumerate(communication_costs)]\n",
    "    \n",
    "    return SIoT_nodes, edges_cmu\n",
    "\n",
    "\n",
    "\n",
    "def assign_SIoT_to_user(node, user, ratio):   \n",
    "    avg_node = int((1-ratio)*node/user)\n",
    "    nodes = list(range(node))\n",
    "    node_distribution = {}\n",
    "    user_distribution = {}\n",
    "    \n",
    "    # assign SIoT to user\n",
    "    for x in range(user):\n",
    "        assign_nodes = sorted(random.sample(nodes, avg_node))\n",
    "        node_distribution[x] = assign_nodes\n",
    "\n",
    "        # remove the assigned nodes\n",
    "        for i in assign_nodes:\n",
    "            nodes.remove(i)\n",
    "\n",
    "    # assign the remaining nodes\n",
    "    node_distribution[\"public\"] = nodes\n",
    "    \n",
    "    \n",
    "    #construct the SIoT-to-user dict.\n",
    "    for u, SIoTs in node_distribution.items():\n",
    "        for s in SIoTs:\n",
    "            user_distribution[s] = u\n",
    "            \n",
    "    return node_distribution, user_distribution\n",
    "\n",
    "\n",
    "#-----------generate the trust table of the users -------------\n",
    "def con_trust_table(n_user):\n",
    "    trust_table = [[0]*n_user for i in range(n_user)]\n",
    "    num_trust = int(n_user*(n_user-1)/2)\n",
    "    trusts = rand_trust(trust_mean, trust_std, num_trust)\n",
    "    for i in range(0, n_user):\n",
    "        trust_table[i][i] = 1.0\n",
    "    k=0\n",
    "    for i in range(0, n_user):\n",
    "        for j in range(i+1, n_user):\n",
    "            trust_table[i][j] = float(format(trusts[k], '.2f'))\n",
    "            trust_table[j][i] = float(format(trusts[k], '.2f'))\n",
    "            k+=1\n",
    "    return trust_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "radio-scanner",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------Step1. SIoT Selection and Clustering ~~~ Function ------------ \n",
    "\n",
    "\n",
    "# ---------compute the vaild number of labels ------------\n",
    "def cmp_vaild_data(data):\n",
    "    v_n_data = 0    # vaild the number of data \n",
    "    for i in range(0, label):\n",
    "        if ((l_num_data[i] - data[i])>=0):\n",
    "            v_n_data += data[i]\n",
    "        else:\n",
    "            v_n_data += l_num_data[i]\n",
    "\n",
    "    return v_n_data\n",
    "\n",
    "\n",
    "# ---------updata the lacking number of labels ------------\n",
    "def update_l_data(data):\n",
    "    print(\"Current the lacking number of labels  :\",l_num_data)\n",
    "    print(\"Current the removing number of labels :\",data)\n",
    "    for i in range(0, label):\n",
    "        total_num_data[i] += data[i]\n",
    "        if ((l_num_data[i] - data[i])>=0):\n",
    "            l_num_data[i] -= data[i]\n",
    "        else:\n",
    "            l_num_data[i] =0\n",
    "\n",
    "    print(\"The lacking number of labels after update:\",l_num_data)\n",
    "    print(\"----------------total data---------------:\",total_num_data)\n",
    "    \n",
    "\n",
    "# --------- compute trust-to-privacy, privacy-to-cost------------\n",
    "def trust_to_privacy(t):\n",
    "    return float(format(epsilon*t/(t+sigma), '.2f'))\n",
    "\n",
    "def trust_to_cost(t):\n",
    "    return float(format((1-trust_to_privacy(t)/epsilon)*p_cost, '.2f'))\n",
    "\n",
    "def privacy_to_cost(p):\n",
    "    return float(format((1-p/epsilon)*p_cost, '.2f'))\n",
    "\n",
    "\n",
    "\n",
    "# --------- get the user who own this SIoT ------------\n",
    "def get_user(i):\n",
    "    return s_u_table[i]\n",
    "\n",
    "\n",
    "# --------- get the trust betweent two SIoT ------------\n",
    "def get_2SIoT_trust(i,j):\n",
    "    \n",
    "    u1 = s_u_table[i]\n",
    "    u2 = s_u_table[j]\n",
    "    \n",
    "    if (u1=='public') or (u2=='public'):\n",
    "        return 1.0\n",
    "    else: \n",
    "        return users_trust[u1][u2]\n",
    "    \n",
    "    \n",
    "    \n",
    "# --------- create new cluster info. ------------    \n",
    "def create_cluster(p):\n",
    "    \n",
    "    G = nx.Graph()\n",
    "    n = [(p[0], G_s.nodes[p[0]]),(p[1], G_s.nodes[p[1]])]\n",
    "    e = [(p[0], p[1], G_s[p[0]][p[1]])]\n",
    "    G.add_nodes_from(n)\n",
    "    G.add_edges_from(e)\n",
    "    cluster_info={\n",
    "        'id': len(clusters),\n",
    "        'graph': G,\n",
    "        'node': [p[0], p[1]],\n",
    "        'p_level': get_2SIoT_trust(p[0], p[1]),\n",
    "        'CH': None,\n",
    "        'total_cmp':0,\n",
    "        'total_cmu':0,\n",
    "        'total_hir':0,\n",
    "        'total_pri':0,\n",
    "        'total_cst':0\n",
    "        \n",
    "    }\n",
    "    clusters.append(cluster_info)    \n",
    "    \n",
    "# --------- find the candidate pair ------------    \n",
    "def find_cnd_c(ps):\n",
    "    cnd_c = None\n",
    "    CP_c = 0\n",
    "    for p in ps :\n",
    "        cmp_cost = G_s.nodes[p[0]]['cmp']+G_s.nodes[p[1]]['cmp']\n",
    "        cmu_cost = G_s[p[0]][p[1]]['cmu']\n",
    "        hir_cost = (G_s.nodes[p[0]]['total_data']+G_s.nodes[p[1]]['total_data'])*u_data\n",
    "\n",
    "        t = get_2SIoT_trust(p[0],p[1])\n",
    "        pri_cost = 2*trust_to_cost(t)\n",
    "        t_cost = cmp_cost + cmu_cost + hir_cost + pri_cost + cc_cost\n",
    "#          print (\"cmp_cost:{}, cmu_cost: {}, hir_cost:{}, pri_cost:{} and t_cost:{}\"\n",
    "#                .format(cmp_cost, cmu_cost, hir_cost, pri_cost, t_cost))\n",
    "\n",
    "\n",
    "        t_dataset = [G_s.nodes[p[0]]['d_data'][i]+G_s.nodes[p[1]]['d_data'][i] for i in range(0, label)]\n",
    "        v_data = cmp_vaild_data(t_dataset)\n",
    "#         print(\"t_dataset:{}, v_data:{}\".format(t_dataset, v_data))\n",
    "\n",
    "        CP = v_data/t_cost\n",
    "#         print (\"CP is \", CP )\n",
    "        \n",
    "        if (CP >= CP_c):\n",
    "            cnd_c = p\n",
    "            CP_c = CP\n",
    "    return cnd_c, CP_c\n",
    "\n",
    "\n",
    "\n",
    "# --------- find the min cmu edge of SIoT i in cluster c------------ \n",
    "def get_min_cmu_edge(i,c):\n",
    "    i_nbr = set(G_s.neighbors(i))\n",
    "    i_nbr = i_nbr & set(c)\n",
    "    cmu = 10000\n",
    "    n = None\n",
    "    for j in i_nbr:\n",
    "        if (cmu>G_s[i][j]['cmu']):\n",
    "            cmu = G_s[i][j]['cmu']\n",
    "            n = j\n",
    "    return n\n",
    "\n",
    "\n",
    "\n",
    "# --------- find the min trust of SIoT i and cluster c------------\n",
    "def get_min_trust(i,c, min_trust):\n",
    "    min_t = min_trust\n",
    "    for j in c:\n",
    "        if (min_t > get_2SIoT_trust(i, j)):\n",
    "            min_t = get_2SIoT_trust(i, j)\n",
    "    return min_t\n",
    "\n",
    "\n",
    "\n",
    "#---------- find the candidate SIoT of each cluster --------------\n",
    "def find_c_SIoTs(cs):\n",
    "    cnd_SIoTs = []\n",
    "    for c in cs:\n",
    "        adj_c =set()\n",
    "        for n in c['node']:\n",
    "            adj_c = adj_c|set(G_s.neighbors(n))\n",
    "        adj_c = adj_c - hired_SIoTs\n",
    "    #     print(adj_c)\n",
    "\n",
    "        cnd_s = None\n",
    "        CP_s = 0\n",
    "        nbr_min_c = None\n",
    "        min_trust = 0\n",
    "        for nbr in adj_c:       \n",
    "            cmp_cost = G_s.nodes[nbr]['cmp']\n",
    "\n",
    "            # find the SIoT that has min cmu edge connected the SIoT nbr in cluster c \n",
    "            nbr_min = get_min_cmu_edge(nbr,c['node'])\n",
    "            cmu_cost = G_s[nbr][nbr_min]['cmu']\n",
    "            hir_cost = G_s.nodes[nbr]['total_data']*u_data\n",
    "\n",
    "            # find the min trust if the SIoT nbr joins the cluster c \n",
    "            nbr_min_t = get_min_trust(nbr, c['node'], c['p_level'])\n",
    "            pri_cost = trust_to_cost(nbr_min_t)\n",
    "\n",
    "            t_cost = cmp_cost + cmu_cost + hir_cost + pri_cost\n",
    "\n",
    "            v_data = cmp_vaild_data(G_s.nodes[nbr]['d_data'])\n",
    "            CP = v_data/t_cost\n",
    "            if (CP >= CP_s):\n",
    "                cnd_s = nbr\n",
    "                CP_s = CP\n",
    "                nbr_min_c = nbr_min\n",
    "                min_trust = nbr_min_t\n",
    "\n",
    "        cnd_SIoT = {'cluster_id': c['id'], 'node_id':cnd_s, 'CP_s': CP_s, \"nbr_min_c\":nbr_min_c,'min_trust': min_trust }\n",
    "        cnd_SIoTs.append(cnd_SIoT)\n",
    "    return cnd_SIoTs\n",
    "\n",
    "\n",
    "\n",
    "#---------- find the highest CP SIoT from all condidate SIoTs --------------\n",
    "def get_c_SIoT(SIoTs):\n",
    "    SIoT = None\n",
    "    CP = 0\n",
    "    for s in SIoTs:\n",
    "        if (s['CP_s'] > CP):\n",
    "            SIoT = s\n",
    "            CP = s['CP_s']\n",
    "    return SIoT\n",
    "\n",
    "\n",
    "\n",
    "#---------- check the data coverage constraint whether has satisfied  --------------\n",
    "def check_data_coverage():\n",
    "    for l in l_num_data:\n",
    "        if(l!=0):\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "checked-drama",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------- Step2. Data balancing for each cluster ~~~ Function ------------\n",
    "\n",
    "\n",
    "#--------- find the cluster with max and min data size ------------\n",
    "def find_max_min_c():\n",
    "    max_c = 0\n",
    "    max_d = sum([G_s.nodes[x]['total_data'] for x in clusters[0]['node']])\n",
    "    min_c = 0\n",
    "    min_d = sum([G_s.nodes[x]['total_data'] for x in clusters[0]['node']])\n",
    "    \n",
    "    for c in clusters:\n",
    "        c_d = sum([G_s.nodes[x]['total_data'] for x in c['node']])\n",
    "        \n",
    "        if (c_d > max_d):\n",
    "            max_d = c_d\n",
    "            max_c = c['id']\n",
    "            continue\n",
    "        if (c_d < min_d):\n",
    "            min_d = c_d\n",
    "            min_c = c['id']\n",
    "    \n",
    "    return max_c, min_c, (max_d-min_d) < D \n",
    "\n",
    "\n",
    "\n",
    "#--------- find the leaf of the cluster ------------\n",
    "def find_leaf_node(c):\n",
    "    leaf = []\n",
    "    for n in c['node']:\n",
    "        if (c['graph'].degree(n) == 1):\n",
    "            leaf.append(n)\n",
    "    return leaf\n",
    "\n",
    "\n",
    "#--------- check remove the node that has still satisfied data coverage constraint  ------------\n",
    "def check_remove_node(l):\n",
    "    lc = [total_num_data[i]-G_s.nodes[l]['d_data'][i] for i in range(0, label)]\n",
    "#     print(l, lc)\n",
    "    for i in range(0, label):\n",
    "        if (total_num_data[i]-G_s.nodes[l]['d_data'][i] < B):\n",
    "            return False\n",
    "    return True\n",
    "            \n",
    "\n",
    "\n",
    "#--------- find the leaf node that satisfies data coverage constraint ------------\n",
    "def find_cd_leaf_node(c):\n",
    "    leaf = find_leaf_node(c)\n",
    "    cd_leaf = []\n",
    "    \n",
    "    for l in leaf:\n",
    "        if (check_remove_node(l)):\n",
    "            cd_leaf.append(l)\n",
    "            \n",
    "    return cd_leaf\n",
    "\n",
    "\n",
    "\n",
    "#--------- find the highest cost node in leaf ------------\n",
    "def find_max_cost_leaf(leaf, c_id):\n",
    "    cost = 0\n",
    "    s_id = None\n",
    "    for l in leaf:\n",
    "        cmp = cmp_cost = G_s.nodes[l]['cmp']\n",
    "        \n",
    "        nbr = list(clusters[c_id]['graph'].neighbors(l))[0]\n",
    "        cmu_cost = G_s[l][nbr]['cmu']\n",
    "        hir_cost = G_s.nodes[l]['total_data']*u_data\n",
    "        t_cost = cmp_cost + cmu_cost + hir_cost\n",
    "#         print (l , t_cost)\n",
    "        if (t_cost > cost):\n",
    "            cost = t_cost\n",
    "            s_id = l\n",
    "    return s_id\n",
    "\n",
    "\n",
    "\n",
    "#--------- find the leaf node that satisfies data coverage constraint ------------\n",
    "def find_highCP_s(c):\n",
    "    adj_c =set()\n",
    "    for n in c['node']:\n",
    "        adj_c = adj_c|set(G_s.neighbors(n))\n",
    "    adj_c = adj_c - hired_SIoTs\n",
    "    #     print(adj_c)\n",
    "    cnd_s = None\n",
    "    CP_s = 0\n",
    "    nbr_min_c = None\n",
    "    min_trust = 0\n",
    "    for nbr in adj_c:       \n",
    "        cmp_cost = G_s.nodes[nbr]['cmp']\n",
    "\n",
    "        # find the SIoT that has min cmu edge connected the SIoT nbr in cluster c \n",
    "        nbr_min = get_min_cmu_edge(nbr,c['node'])\n",
    "        cmu_cost = G_s[nbr][nbr_min]['cmu']\n",
    "        hir_cost = G_s.nodes[nbr]['total_data']*u_data\n",
    "\n",
    "        # find the min trust if the SIoT nbr joins the cluster c \n",
    "        nbr_min_t = get_min_trust(nbr, c['node'], c['p_level'])\n",
    "        pri_cost = trust_to_cost(nbr_min_t)\n",
    "\n",
    "        t_cost = cmp_cost + cmu_cost + hir_cost + pri_cost\n",
    "\n",
    "        CP = G_s.nodes[nbr]['total_data']/t_cost\n",
    "        if (CP >= CP_s):\n",
    "            cnd_s = nbr\n",
    "            CP_s = CP\n",
    "            nbr_min_c = nbr_min\n",
    "            min_trust = nbr_min_t\n",
    "\n",
    "    cnd_SIoT = {'cluster_id': c['id'], 'node_id':cnd_s, 'CP_s': CP_s, \"nbr_min_c\":nbr_min_c,'min_trust': min_trust }\n",
    "    \n",
    "    return cnd_SIoT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aggregate-ancient",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------- Step 3. Cluster head(CH) decision and Rerouting ~~~functoin ------------\n",
    "\n",
    "# --------- get the minimum privacy level of node n on path p and the node that let n has this privacy requirment ------------\n",
    "def get_min_plevel(n, p):\n",
    "    min_p = 1\n",
    "    pri_n = None\n",
    "    for i in p:\n",
    "        if (get_2SIoT_trust(n, i) < min_p):\n",
    "            min_p = get_2SIoT_trust(n, i)\n",
    "            pri_n = i\n",
    "    return min_p, pri_n\n",
    "\n",
    "\n",
    "# --------- get the total cost if node n is cluster head ------------\n",
    "def get_total_cost(n, c):\n",
    "    nodes = c['node']\n",
    "    s_ps = []    # record shortest paths of all node to node n\n",
    "    total_cmu = 0\n",
    "    total_pri = 0\n",
    "    min_p_level = 1\n",
    "    # get all shortest paths\n",
    "    for i in nodes:\n",
    "        if (i == n):\n",
    "            continue\n",
    "        s_ps.append(nx.shortest_path(c['graph'],source=i,target=n, weight='cmu'))\n",
    "        \n",
    "    # compute total communication cost\n",
    "    for sp in s_ps:\n",
    "        for i in range(1, len(sp)):\n",
    "            total_cmu += G_s[sp[i-1]][sp[i]]['cmu']\n",
    "    \n",
    "    #find the min p level\n",
    "    for sp in s_ps:\n",
    "        min_p, _ = get_min_plevel(sp[0], sp)\n",
    "        if (min_p < min_p_level):\n",
    "            min_p_level = min_p\n",
    "    \n",
    "    #compute the total privacy cost\n",
    "    total_pri = len(nodes)*trust_to_cost(min_p_level) \n",
    "#     print(min_p_level)\n",
    "\n",
    "    return total_cmu + total_pri\n",
    "\n",
    "\n",
    "\n",
    "# --------- get the node with minimum total cost in the cluster c ------------\n",
    "def get_ch(c_ch, c):\n",
    "    ch = None\n",
    "    cost = 9999999\n",
    "    for n in c_ch:\n",
    "        n_cost = get_total_cost(n, c)\n",
    "#         print (n_cost , n)\n",
    "        if (n_cost<cost):\n",
    "            cost = n_cost\n",
    "            ch = n\n",
    "    return ch\n",
    "\n",
    "\n",
    "\n",
    "# --------- set node ch as the cluster head of the cluster c ------------\n",
    "def set_ch(ch, c):\n",
    "    c_id = c['id']\n",
    "    nodes = c['node']\n",
    "    s_ps = []    # record shortest paths of all node to node n\n",
    "    total_cmp = sum([G_s.nodes[i]['cmp'] for i in nodes])\n",
    "    total_cmu = 0\n",
    "    total_hir = sum([G_s.nodes[i]['total_data'] for i in nodes])*u_data\n",
    "    total_pri = 0\n",
    "    min_p_level = 1\n",
    "    # get all shortest paths\n",
    "    for i in nodes:\n",
    "        if (i == ch):\n",
    "            continue\n",
    "        s_ps.append(nx.shortest_path(c['graph'],source=i,target=ch, weight='cmu'))\n",
    "        \n",
    "    # compute total communication cost\n",
    "    for sp in s_ps:\n",
    "        for i in range(1, len(sp)):\n",
    "            total_cmu += G_s[sp[i-1]][sp[i]]['cmu']\n",
    "    \n",
    "    #find the min p level\n",
    "    for sp in s_ps:\n",
    "        min_p, pri_n = get_min_plevel(sp[0], sp)\n",
    "        \n",
    "        #set node info\n",
    "        c['graph'].nodes[sp[0]]['p_level'] = min_p\n",
    "        c['graph'].nodes[sp[0]]['pri_n'] = pri_n\n",
    "        \n",
    "        if (min_p < min_p_level):\n",
    "            min_p_level = min_p\n",
    "    c['graph'].nodes[ch]['p_level'] = 1\n",
    "    c['graph'].nodes[ch]['pri_n'] = ch\n",
    "    \n",
    "    \n",
    "    #compute the total privacy cost\n",
    "    total_pri = len(nodes)*trust_to_cost(min_p_level) \n",
    "    \n",
    "    # set cluster info \n",
    "    clusters[c_id]['p_level'] = min_p_level\n",
    "    clusters[c_id]['CH'] = ch\n",
    "    clusters[c_id]['total_cmp'] = total_cmp\n",
    "    clusters[c_id]['total_cmu'] = total_cmu\n",
    "    clusters[c_id]['total_hir'] = float(format(total_hir, '.2f'))\n",
    "    clusters[c_id]['total_pri'] = float(format(total_pri, '.2f'))\n",
    "    clusters[c_id]['total_cst'] = total_cmp + total_cmu + float(format(total_hir, '.2f')) + float(format(total_pri, '.2f'))\n",
    "    \n",
    "    \n",
    "\n",
    "# get the minimum privacy level node in the cluster c\n",
    "def get_min_pl_n(c):\n",
    "    \n",
    "    min_n = None\n",
    "    min_l = 1\n",
    "    for i in list(c['node']):\n",
    "#         print (i , c['graph'].nodes[i]['p_level'])\n",
    "        if (c['graph'].nodes[i]['p_level'] < min_l):\n",
    "            min_n = i\n",
    "            min_l = c['graph'].nodes[i]['p_level']\n",
    "    \n",
    "    return min_n\n",
    "    \n",
    "# compute the total cost\n",
    "def cmp_t_cost(G, ch):\n",
    "    \n",
    "    nodes = G.nodes()\n",
    "    s_ps = []    # record shortest paths of all node to node n\n",
    "    total_cmp = sum([G_s.nodes[i]['cmp'] for i in nodes])\n",
    "    total_cmu = 0\n",
    "    total_hir = sum([G_s.nodes[i]['total_data'] for i in nodes])*u_data\n",
    "    total_pri = 0\n",
    "    min_p_level = 1\n",
    "    # get all shortest paths\n",
    "    for i in nodes:\n",
    "        if (i == ch):\n",
    "            continue\n",
    "        try:\n",
    "            s_ps.append(nx.shortest_path(G,source=i,target=ch, weight='cmu'))\n",
    "        except:\n",
    "            return 100000\n",
    "    # compute total communication cost\n",
    "    for sp in s_ps:\n",
    "        for i in range(1, len(sp)):\n",
    "            total_cmu += G_s[sp[i-1]][sp[i]]['cmu']\n",
    "    \n",
    "    #find the min p level\n",
    "    for sp in s_ps:\n",
    "        min_p, pri_n = get_min_plevel(sp[0], sp)\n",
    "        \n",
    "        if (min_p < min_p_level):\n",
    "            min_p_level = min_p\n",
    "    \n",
    "    \n",
    "    #compute the total privacy cost\n",
    "    total_pri = len(nodes)*trust_to_cost(min_p_level) \n",
    "    \n",
    "    return total_cmp + total_cmu + total_pri + total_hir\n",
    "\n",
    "\n",
    "\n",
    "#  rerouting\n",
    "def rerouting(c):\n",
    "    min_n = get_min_pl_n(c)\n",
    "    pri_n = c['graph'].nodes[min_n]['pri_n']\n",
    "    path = nx.shortest_path(c['graph'],source=min_n,target=pri_n, weight='cmu')\n",
    "    \n",
    "    G_c = nx.Graph(G_s)\n",
    "    nodes = set(G_c.nodes) - set(c['node'])\n",
    "    G_c.remove_nodes_from(list(nodes))\n",
    "#     nx.draw(G_c)\n",
    "    ori = None\n",
    "    cnd = None\n",
    "    t_cost = c['total_cst']\n",
    "    \n",
    "    for n in list(path)[:-1]:\n",
    "        cnd_e = G_c.edges([n])\n",
    "        ori_e = None\n",
    "#         print(G_c.edges([n]))\n",
    "        # find original edge of the node n \n",
    "        for e in cnd_e:\n",
    "            if e in list(c['graph'].edges) or (e[1],e[0]) in list(c['graph'].edges):\n",
    "                ori_e = e\n",
    "        \n",
    "        for e in cnd_e:\n",
    "            # skip the original path \n",
    "            if e in list(c['graph'].edges) or (e[1],e[0]) in list(c['graph'].edges):\n",
    "                continue\n",
    "                \n",
    "            G_d = nx.Graph(c['graph'])\n",
    "#             print(e, ori_e)\n",
    "            \n",
    "            G_d.remove_edges_from([ori_e])\n",
    "            \n",
    "            G_d.add_edges_from([(e[0], e[1], G_s[e[0]][e[1]])])\n",
    "            \n",
    "            cost = cmp_t_cost(G_d, c['CH'])\n",
    "            \n",
    "            if (t_cost > cost):\n",
    "                t_cost = cost\n",
    "                ori = ori_e\n",
    "                cnd = e\n",
    "#             print(t_cost, c['total_cst'])\n",
    "#     print(ori, cnd)\n",
    "    return ori, cnd, ori != None\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#  exchange the two edge \n",
    "def change_route(ori_e, rerout_e, c_id):\n",
    "    clusters[c_id]['graph'].remove_edges_from([ori_e])        \n",
    "    clusters[c_id]['graph'].add_edges_from([(rerout_e[0], rerout_e[1], G_s[rerout_e[0]][rerout_e[1]])])\n",
    "    print (\"change {} to {}\".format(ori_e, rerout_e))\n",
    "    \n",
    "    \n",
    "    \n",
    "def update_c_info (c_id): \n",
    "    nodes = clusters[c_id]['node']\n",
    "    ch = clusters[c_id]['CH']\n",
    "    ori_cost = clusters[c_id]['total_cst']\n",
    "    s_ps = []    # record shortest paths of all node to node n\n",
    "    total_cmp = sum([G_s.nodes[i]['cmp'] for i in nodes])\n",
    "    total_cmu = 0\n",
    "    total_hir = sum([G_s.nodes[i]['total_data'] for i in nodes])*u_data\n",
    "    total_pri = 0\n",
    "    min_p_level = 1\n",
    "    # get all shortest paths\n",
    "    for i in nodes:\n",
    "        if (i == ch):\n",
    "            continue\n",
    "        s_ps.append(nx.shortest_path(clusters[c_id]['graph'],source=i,target=ch, weight='cmu'))\n",
    "        \n",
    "    # compute total communication cost\n",
    "    for sp in s_ps:\n",
    "        for i in range(1, len(sp)):\n",
    "            total_cmu += G_s[sp[i-1]][sp[i]]['cmu']\n",
    "    \n",
    "    #find the min p level\n",
    "    for sp in s_ps:\n",
    "        min_p, pri_n = get_min_plevel(sp[0], sp)\n",
    "        \n",
    "        #set node info\n",
    "        clusters[c_id]['graph'].nodes[sp[0]]['p_level'] = min_p\n",
    "        clusters[c_id]['graph'].nodes[sp[0]]['pri_n'] = pri_n\n",
    "        \n",
    "        if (min_p < min_p_level):\n",
    "            min_p_level = min_p\n",
    "    \n",
    "    #compute the total privacy cost\n",
    "    total_pri = len(nodes)*trust_to_cost(min_p_level) \n",
    "    \n",
    "    # set cluster info \n",
    "    clusters[c_id]['p_level'] = min_p_level\n",
    "    clusters[c_id]['total_cmp'] = total_cmp\n",
    "    clusters[c_id]['total_cmu'] = total_cmu\n",
    "    clusters[c_id]['total_hir'] = float(format(total_hir, '.2f'))\n",
    "    clusters[c_id]['total_pri'] = float(format(total_pri, '.2f'))\n",
    "    clusters[c_id]['total_cst'] = total_cmp + total_cmu + float(format(total_hir, '.2f')) + float(format(total_pri, '.2f'))\n",
    "    \n",
    "    return ori_cost - clusters[c_id]['total_cst']\n",
    "\n",
    "\n",
    "\n",
    "def get_overall_cost():\n",
    "    overall_cmp = sum([c['total_cmp'] for c in clusters])\n",
    "    overall_cmu = sum([c['total_cmu'] for c in clusters])\n",
    "    overall_hir = sum([c['total_hir'] for c in clusters])\n",
    "    overall_pri = sum([c['total_pri'] for c in clusters])\n",
    "    \n",
    "    overall_cst = overall_cmp + overall_cmu + overall_hir + overall_pri\n",
    "    \n",
    "    return [overall_cmp, overall_cmu, overall_hir, overall_pri, overall_cst]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ordered-malpractice",
   "metadata": {},
   "outputs": [],
   "source": [
    "# node info\n",
    "num_node = 200\n",
    "node_degree = 10\n",
    "computation_mean = 6\n",
    "computation_std = 2\n",
    "communication_mean = 6\n",
    "communication_std = 2\n",
    "public_ratio = 0.1\n",
    "cc_cost = 10      #communication cost of connected cloud\n",
    "\n",
    "# user info\n",
    "num_user =int(num_node/30)\n",
    "trust_mean = 0.75\n",
    "trust_std = 0.3\n",
    "u_s_table = {}   # user-to-SIoT table\n",
    "s_u_table = {}   # SIoT-to-user table\n",
    "users_trust=[]   # trust table\n",
    "\n",
    "# data distribution\n",
    "label = 10\n",
    "IID = True\n",
    "primary = 0.6\n",
    "data_mean = 300\n",
    "data_std_ratio = 0.3    #need to less than 0.45\n",
    "label_std_ratio = 0.1   #need to less than 0.45\n",
    "\n",
    "# hiring cost\n",
    "u_data = 0.01   # unit data cost\n",
    "hired_SIoTs =set()\n",
    "\n",
    "# privacy setting\n",
    "sigma = 0.25      # adjustable parameter ~[0,1]\n",
    "epsilon = 15      # privacy intensity parameter\n",
    "p_cost = 30       # privacy cost\n",
    "\n",
    "# data coverage threshold\n",
    "B = 2000\n",
    "l_num_data = [B]*label\n",
    "total_num_data = [0]*label\n",
    "\n",
    "# data balancing threshold\n",
    "D = 800\n",
    "\n",
    "#cluster info \n",
    "clusters=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "outside-secretary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for example \n",
    "\n",
    "# node info\n",
    "num_node = 20\n",
    "node_degree = 2\n",
    "computation_mean = 6\n",
    "computation_std = 2\n",
    "communication_mean = 6\n",
    "communication_std = 2\n",
    "public_ratio = 0.2\n",
    "cc_cost = 10      #communication cost of connected cloud\n",
    "\n",
    "# user info\n",
    "num_user = 6\n",
    "trust_mean = 0.75\n",
    "trust_std = 0.3\n",
    "u_s_table = {}   # user-to-SIoT table\n",
    "s_u_table = {}   # SIoT-to-user table\n",
    "users_trust=[]   # trust table\n",
    "\n",
    "# data distribution\n",
    "label = 5\n",
    "IID = False\n",
    "primary = 0.6\n",
    "data_mean = 20\n",
    "data_std_ratio = 0.3    #need to less than 0.45\n",
    "label_std_ratio = 0.1   #need to less than 0.45\n",
    "\n",
    "# hiring cost\n",
    "u_data = 0.01   # unit data cost\n",
    "hired_SIoTs =set()\n",
    "\n",
    "# privacy setting\n",
    "sigma = 0.25      # adjustable parameter ~[0,1]\n",
    "epsilon = 15      # privacy intensity parameter\n",
    "p_cost = 30       # privacy cost\n",
    "\n",
    "# data coverage threshold\n",
    "B = 35\n",
    "l_num_data = [B]*label\n",
    "total_num_data = [0]*label\n",
    "\n",
    "# data balancing threshold\n",
    "D = 20\n",
    "\n",
    "#cluster info \n",
    "clusters=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "amended-processing",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The system has 20 SIoTs and 6 users\n",
      "total data: 424\n",
      "Data distribution is non-IID.\n"
     ]
    }
   ],
   "source": [
    "# for example \n",
    "\n",
    "# node info\n",
    "num_node = 20\n",
    "node_degree = 2\n",
    "computation_mean = 6\n",
    "computation_std = 2\n",
    "communication_mean = 6\n",
    "communication_std = 2\n",
    "public_ratio = 0.2\n",
    "cc_cost = 10      #communication cost of connected cloud\n",
    "\n",
    "# user info\n",
    "num_user = 6\n",
    "trust_mean = 0.75\n",
    "trust_std = 0.3\n",
    "u_s_table = {}   # user-to-SIoT table\n",
    "s_u_table = {}   # SIoT-to-user table\n",
    "users_trust=[]   # trust table\n",
    "\n",
    "# data distribution\n",
    "label = 5\n",
    "IID = False\n",
    "primary = 0.6\n",
    "data_mean = 20\n",
    "data_std_ratio = 0.3    #need to less than 0.45\n",
    "label_std_ratio = 0.1   #need to less than 0.45\n",
    "\n",
    "# hiring cost\n",
    "u_data = 0.01   # unit data cost\n",
    "hired_SIoTs =set()\n",
    "\n",
    "# privacy setting\n",
    "sigma = 0.25      # adjustable parameter ~[0,1]\n",
    "epsilon = 15      # privacy intensity parameter\n",
    "p_cost = 30       # privacy cost\n",
    "\n",
    "# data coverage threshold\n",
    "B = 35\n",
    "l_num_data = [B]*label\n",
    "total_num_data = [0]*label\n",
    "\n",
    "# data balancing threshold\n",
    "D = 20\n",
    "\n",
    "#cluster info \n",
    "clusters=[]\n",
    "\n",
    "#---------------create SIoT topology and user trust------------------\n",
    "print (\"The system has {} SIoTs and {} users\".format(num_node, num_user))\n",
    "G_s = nx.Graph()\n",
    "V_s, E_s = generated_node(num_node, node_degree, \n",
    "                            computation_mean, computation_std, \n",
    "                            communication_mean, communication_std,\n",
    "                            label, IID, primary, data_mean, data_std_ratio, label_std_ratio)\n",
    "G_s.add_nodes_from(V_s)\n",
    "G_s.add_edges_from(E_s)\n",
    "\n",
    "\n",
    "# assign the SIoTs to the users\n",
    "u_s_table, s_u_table = assign_SIoT_to_user(num_node, num_user, public_ratio)\n",
    "\n",
    "# compute trust between each user(i.e., construct the trust table)\n",
    "users_trust = con_trust_table(num_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "familiar-scale",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The initial Cluster is (8, 11)\n",
      "Current the lacking number of labels  : [35, 35, 35, 35, 35]\n",
      "Current the removing number of labels : [2, 2, 31, 2, 2]\n",
      "The lacking number of labels after update: [33, 33, 4, 33, 33]\n",
      "----------------total data---------------: [2, 2, 31, 2, 2]\n",
      "Remove the node 8 and 11 from G_r\n",
      "\n",
      "\n",
      "---------------- Round 0 ---------------\n",
      "add the node 9 to the cluster 0\n",
      "Current the lacking number of labels  : [33, 33, 4, 33, 33]\n",
      "Current the removing number of labels : [13, 1, 1, 1, 1]\n",
      "The lacking number of labels after update: [20, 32, 3, 32, 32]\n",
      "----------------total data---------------: [15, 3, 32, 3, 3]\n",
      "Remove the node 9 from G_r\n",
      "\n",
      "\n",
      "---------------- Round 1 ---------------\n",
      "add the node 2 to the cluster 0\n",
      "Current the lacking number of labels  : [20, 32, 3, 32, 32]\n",
      "Current the removing number of labels : [1, 1, 1, 1, 16]\n",
      "The lacking number of labels after update: [19, 31, 2, 31, 16]\n",
      "----------------total data---------------: [16, 4, 33, 4, 19]\n",
      "Remove the node 2 from G_r\n",
      "\n",
      "\n",
      "---------------- Round 2 ---------------\n",
      "add the node 6 to the cluster 0\n",
      "Current the lacking number of labels  : [19, 31, 2, 31, 16]\n",
      "Current the removing number of labels : [1, 1, 1, 1, 15]\n",
      "The lacking number of labels after update: [18, 30, 1, 30, 1]\n",
      "----------------total data---------------: [17, 5, 34, 5, 34]\n",
      "Remove the node 6 from G_r\n",
      "\n",
      "\n",
      "---------------- Round 3 ---------------\n",
      "add the node 5 to the cluster 0\n",
      "Current the lacking number of labels  : [18, 30, 1, 30, 1]\n",
      "Current the removing number of labels : [15, 1, 1, 1, 1]\n",
      "The lacking number of labels after update: [3, 29, 0, 29, 0]\n",
      "----------------total data---------------: [32, 6, 35, 6, 35]\n",
      "Remove the node 5 from G_r\n",
      "\n",
      "\n",
      "---------------- Round 4 ---------------\n",
      "add the node 10 to the cluster 0\n",
      "Current the lacking number of labels  : [3, 29, 0, 29, 0]\n",
      "Current the removing number of labels : [1, 1, 1, 15, 1]\n",
      "The lacking number of labels after update: [2, 28, 0, 14, 0]\n",
      "----------------total data---------------: [33, 7, 36, 21, 36]\n",
      "Remove the node 10 from G_r\n",
      "\n",
      "\n",
      "---------------- Round 5 ---------------\n",
      "create the new cluster (7,16) as cluster 1\n",
      "Current the lacking number of labels  : [2, 28, 0, 14, 0]\n",
      "Current the removing number of labels : [2, 14, 2, 11, 2]\n",
      "The lacking number of labels after update: [0, 14, 0, 3, 0]\n",
      "----------------total data---------------: [35, 21, 38, 32, 38]\n",
      "Remove the node 7 and 16 from G_r\n",
      "\n",
      "\n",
      "---------------- Round 6 ---------------\n",
      "add the node 18 to the cluster 0\n",
      "Current the lacking number of labels  : [0, 14, 0, 3, 0]\n",
      "Current the removing number of labels : [1, 10, 1, 1, 1]\n",
      "The lacking number of labels after update: [0, 4, 0, 2, 0]\n",
      "----------------total data---------------: [36, 31, 39, 33, 39]\n",
      "Remove the node 18 from G_r\n",
      "\n",
      "\n",
      "---------------- Round 7 ---------------\n",
      "add the node 12 to the cluster 0\n",
      "Current the lacking number of labels  : [0, 4, 0, 2, 0]\n",
      "Current the removing number of labels : [1, 9, 1, 1, 1]\n",
      "The lacking number of labels after update: [0, 0, 0, 1, 0]\n",
      "----------------total data---------------: [37, 40, 40, 34, 40]\n",
      "Remove the node 12 from G_r\n",
      "\n",
      "\n",
      "---------------- Round 8 ---------------\n",
      "add the node 3 to the cluster 1\n",
      "Current the lacking number of labels  : [0, 0, 0, 1, 0]\n",
      "Current the removing number of labels : [1, 1, 1, 1, 13]\n",
      "The lacking number of labels after update: [0, 0, 0, 0, 0]\n",
      "----------------total data---------------: [38, 41, 41, 35, 53]\n",
      "Remove the node 3 from G_r\n"
     ]
    }
   ],
   "source": [
    "# ---------Step1. SIoT Selection and Clustering ------------ \n",
    "\n",
    "G_r = nx.Graph(G_s)\n",
    "pairs = list(G_r.edges())\n",
    "\n",
    "# construct the initial cluster\n",
    "init_pair, _ = find_cnd_c(pairs)\n",
    "print (\"The initial Cluster is {}\".format(init_pair))\n",
    "init_dataset = [G_s.nodes[init_pair[0]]['d_data'][i]+G_s.nodes[init_pair[1]]['d_data'][i] for i in range(0, label)]\n",
    "update_l_data(init_dataset)\n",
    "\n",
    "#  record the cluster info.\n",
    "create_cluster(init_pair)\n",
    "\n",
    "# record the hired SIoTs\n",
    "hired_SIoTs.update([init_pair[0], init_pair[1]])      \n",
    "\n",
    "# remove initial cluster \n",
    "G_r.remove_nodes_from([init_pair[0] ,init_pair[1] ])\n",
    "# print (\"Remove the node {} and {} from G_r\".format(init_pair[0] ,init_pair[1]))\n",
    "round = 0\n",
    "while (not(check_data_coverage())):\n",
    "    \n",
    "    print('\\n')\n",
    "    print('---------------- Round {} ---------------'.format(round))\n",
    "    round+=1\n",
    "    \n",
    "    c_SIoT = None\n",
    "    \n",
    "    #  find the candidate SIoT of each cluster\n",
    "    c_SIoTs = find_c_SIoTs(clusters)\n",
    "    \n",
    "    # get the highest CP SIoT from all condidate SIoTs\n",
    "    c_SIoT = get_c_SIoT(c_SIoTs)\n",
    "    \n",
    "    # find the candidate cluster\n",
    "    pairs = list(G_r.edges())\n",
    "    c_pair, c_CP = find_cnd_c(pairs) \n",
    "    \n",
    "#     print (c_SIoTs)\n",
    "#     print(c_SIoT)\n",
    "#     print(\"The c_pair:{}, CP:{} \".format(c_pair, c_CP))\n",
    "    \n",
    "    # compare the CP between the c_SIoT and c_pair \n",
    "    if (c_SIoT['CP_s'] >= c_CP and (c_SIoT['CP_s'] != None)):\n",
    "        # add the c_SIoT to coressponding cluster\n",
    "        cluster_id = c_SIoT['cluster_id']\n",
    "        node_id = c_SIoT['node_id']\n",
    "        print(\"add the node {} to the cluster {}\".format(node_id, cluster_id))\n",
    "                \n",
    "        clusters[cluster_id]['node'].append(node_id)\n",
    "        clusters[cluster_id]['p_level'] = c_SIoT['min_trust']\n",
    "        clusters[cluster_id]['graph'].add_nodes_from([(node_id, G_s.nodes[node_id] )])\n",
    "        clusters[cluster_id]['graph'].add_edges_from([(node_id, c_SIoT['nbr_min_c'], G_s[node_id][c_SIoT['nbr_min_c']])])\n",
    "        update_l_data(G_s.nodes[node_id]['d_data'])\n",
    "        hired_SIoTs.add(node_id)\n",
    "        \n",
    "        print (\"Remove the node {} from G_r\".format(node_id))\n",
    "        G_r.remove_node(node_id)\n",
    "    \n",
    "    else:\n",
    "        print(\"create the new cluster ({},{}) as cluster {}\".format(c_pair[0] ,c_pair[1], len(clusters)))\n",
    "              \n",
    "        c_dataset = [G_s.nodes[c_pair[0]]['d_data'][i]+G_s.nodes[c_pair[1]]['d_data'][i] for i in range(0, label)]\n",
    "        update_l_data(c_dataset)\n",
    "\n",
    "        #  record the cluster info.\n",
    "        create_cluster(c_pair)\n",
    "\n",
    "        # record the hired SIoTs\n",
    "        hired_SIoTs.update([c_pair[0], c_pair[1]])      \n",
    "\n",
    "        # remove initial cluster \n",
    "        G_r.remove_nodes_from([c_pair[0] ,c_pair[1] ])\n",
    "        print (\"Remove the node {} and {} from G_r\".format(c_pair[0] ,c_pair[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "victorian-shepherd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------- Step2. Data balancing for each cluster ------------\n",
      "\n",
      "\n",
      "---------------- Round 1 ---------------\n",
      "add the node 177 to the cluster 9\n",
      "Remove the node 177 from G_r\n",
      "-------total data before removing node: [2092, 2019, 2020, 2042, 2036, 2016, 2033, 2011, 2051, 2026]\n",
      "Current the adding number of labels : [38, 37, 35, 33, 46, 39, 41, 39, 40, 35]\n",
      "-------total data after removing node : [2130, 2056, 2055, 2075, 2082, 2055, 2074, 2050, 2091, 2061]\n",
      "\n",
      "\n",
      "---------------- Round 2 ---------------\n",
      "Remove node 159 form the cluster 7\n",
      "-------total data before removing node: [2130, 2056, 2055, 2075, 2082, 2055, 2074, 2050, 2091, 2061]\n",
      "Current the removing number of labels : [38, 38, 39, 34, 42, 32, 41, 40, 37, 40]\n",
      "-------total data after removing node : [2092, 2018, 2016, 2041, 2040, 2023, 2033, 2010, 2054, 2021]\n",
      "\n",
      "\n",
      "---------------- Round 3 ---------------\n",
      "add the node 162 to the cluster 4\n",
      "Remove the node 162 from G_r\n",
      "-------total data before removing node: [2092, 2018, 2016, 2041, 2040, 2023, 2033, 2010, 2054, 2021]\n",
      "Current the adding number of labels : [27, 27, 31, 26, 24, 28, 29, 30, 29, 25]\n",
      "-------total data after removing node : [2119, 2045, 2047, 2067, 2064, 2051, 2062, 2040, 2083, 2046]\n",
      "\n",
      "\n",
      "---------------- Round 4 ---------------\n",
      "Remove node 121 form the cluster 7\n",
      "-------total data before removing node: [2119, 2045, 2047, 2067, 2064, 2051, 2062, 2040, 2083, 2046]\n",
      "Current the removing number of labels : [37, 31, 36, 40, 41, 32, 37, 39, 35, 34]\n",
      "-------total data after removing node : [2082, 2014, 2011, 2027, 2023, 2019, 2025, 2001, 2048, 2012]\n",
      "\n",
      "\n",
      "---------------- Round 5 ---------------\n",
      "add the node 121 to the cluster 5\n",
      "Remove the node 121 from G_r\n",
      "-------total data before removing node: [2082, 2014, 2011, 2027, 2023, 2019, 2025, 2001, 2048, 2012]\n",
      "Current the adding number of labels : [37, 31, 36, 40, 41, 32, 37, 39, 35, 34]\n",
      "-------total data after removing node : [2119, 2045, 2047, 2067, 2064, 2051, 2062, 2040, 2083, 2046]\n",
      "\n",
      "\n",
      "---------------- Round 6 ---------------\n",
      "Remove node 93 form the cluster 3\n",
      "-------total data before removing node: [2119, 2045, 2047, 2067, 2064, 2051, 2062, 2040, 2083, 2046]\n",
      "Current the removing number of labels : [40, 39, 44, 44, 43, 32, 35, 39, 48, 45]\n",
      "-------total data after removing node : [2079, 2006, 2003, 2023, 2021, 2019, 2027, 2001, 2035, 2001]\n",
      "\n",
      "\n",
      "---------------- Round 7 ---------------\n",
      "add the node 93 to the cluster 8\n",
      "Remove the node 93 from G_r\n",
      "-------total data before removing node: [2079, 2006, 2003, 2023, 2021, 2019, 2027, 2001, 2035, 2001]\n",
      "Current the adding number of labels : [40, 39, 44, 44, 43, 32, 35, 39, 48, 45]\n",
      "-------total data after removing node : [2119, 2045, 2047, 2067, 2064, 2051, 2062, 2040, 2083, 2046]\n",
      "\n",
      "\n",
      "---------------- Round 8 ---------------\n",
      "Remove node 191 form the cluster 0\n",
      "-------total data before removing node: [2119, 2045, 2047, 2067, 2064, 2051, 2062, 2040, 2083, 2046]\n",
      "Current the removing number of labels : [36, 34, 38, 37, 35, 36, 36, 37, 34, 37]\n",
      "-------total data after removing node : [2083, 2011, 2009, 2030, 2029, 2015, 2026, 2003, 2049, 2009]\n",
      "\n",
      "\n",
      "---------------- Round 9 ---------------\n",
      "add the node 65 to the cluster 9\n",
      "Remove the node 65 from G_r\n",
      "-------total data before removing node: [2083, 2011, 2009, 2030, 2029, 2015, 2026, 2003, 2049, 2009]\n",
      "Current the adding number of labels : [40, 35, 35, 39, 38, 38, 38, 32, 33, 43]\n",
      "-------total data after removing node : [2123, 2046, 2044, 2069, 2067, 2053, 2064, 2035, 2082, 2052]\n",
      "\n",
      "\n",
      "---------------- Round 10 ---------------\n",
      "Remove node 8 form the cluster 7\n",
      "-------total data before removing node: [2123, 2046, 2044, 2069, 2067, 2053, 2064, 2035, 2082, 2052]\n",
      "Current the removing number of labels : [26, 23, 22, 24, 21, 24, 26, 24, 22, 21]\n",
      "-------total data after removing node : [2097, 2023, 2022, 2045, 2046, 2029, 2038, 2011, 2060, 2031]\n",
      "\n",
      "\n",
      "---------------- Round 11 ---------------\n",
      "add the node 77 to the cluster 4\n",
      "Remove the node 77 from G_r\n",
      "-------total data before removing node: [2097, 2023, 2022, 2045, 2046, 2029, 2038, 2011, 2060, 2031]\n",
      "Current the adding number of labels : [40, 40, 34, 32, 37, 34, 43, 34, 39, 35]\n",
      "-------total data after removing node : [2137, 2063, 2056, 2077, 2083, 2063, 2081, 2045, 2099, 2066]\n",
      "\n",
      "\n",
      "---------------- Round 12 ---------------\n",
      "Remove node 32 form the cluster 3\n",
      "-------total data before removing node: [2137, 2063, 2056, 2077, 2083, 2063, 2081, 2045, 2099, 2066]\n",
      "Current the removing number of labels : [40, 37, 37, 35, 35, 31, 34, 33, 25, 32]\n",
      "-------total data after removing node : [2097, 2026, 2019, 2042, 2048, 2032, 2047, 2012, 2074, 2034]\n",
      "\n",
      "\n",
      "---------------- Round 13 ---------------\n",
      "add the node 95 to the cluster 2\n",
      "Remove the node 95 from G_r\n",
      "-------total data before removing node: [2097, 2026, 2019, 2042, 2048, 2032, 2047, 2012, 2074, 2034]\n",
      "Current the adding number of labels : [34, 32, 33, 37, 34, 34, 38, 34, 32, 35]\n",
      "-------total data after removing node : [2131, 2058, 2052, 2079, 2082, 2066, 2085, 2046, 2106, 2069]\n",
      "\n",
      "\n",
      "---------------- Round 14 ---------------\n",
      "Remove node 108 form the cluster 7\n",
      "-------total data before removing node: [2131, 2058, 2052, 2079, 2082, 2066, 2085, 2046, 2106, 2069]\n",
      "Current the removing number of labels : [46, 46, 45, 38, 44, 45, 41, 44, 33, 39]\n",
      "-------total data after removing node : [2085, 2012, 2007, 2041, 2038, 2021, 2044, 2002, 2073, 2030]\n",
      "\n",
      "\n",
      "---------------- Round 15 ---------------\n",
      "add the node 101 to the cluster 5\n",
      "Remove the node 101 from G_r\n",
      "-------total data before removing node: [2085, 2012, 2007, 2041, 2038, 2021, 2044, 2002, 2073, 2030]\n",
      "Current the adding number of labels : [37, 37, 37, 30, 40, 34, 38, 33, 32, 38]\n",
      "-------total data after removing node : [2122, 2049, 2044, 2071, 2078, 2055, 2082, 2035, 2105, 2068]\n",
      "\n",
      "\n",
      "---------------- Round 16 ---------------\n",
      "Remove node 174 form the cluster 0\n",
      "-------total data before removing node: [2122, 2049, 2044, 2071, 2078, 2055, 2082, 2035, 2105, 2068]\n",
      "Current the removing number of labels : [15, 14, 17, 15, 18, 17, 14, 16, 21, 17]\n",
      "-------total data after removing node : [2107, 2035, 2027, 2056, 2060, 2038, 2068, 2019, 2084, 2051]\n",
      "\n",
      "\n",
      "---------------- Round 17 ---------------\n",
      "add the node 172 to the cluster 8\n",
      "Remove the node 172 from G_r\n",
      "-------total data before removing node: [2107, 2035, 2027, 2056, 2060, 2038, 2068, 2019, 2084, 2051]\n",
      "Current the adding number of labels : [34, 36, 26, 41, 41, 47, 39, 43, 47, 38]\n",
      "-------total data after removing node : [2141, 2071, 2053, 2097, 2101, 2085, 2107, 2062, 2131, 2089]\n",
      "\n",
      "\n",
      "---------------- Round 18 ---------------\n",
      "Remove node 134 form the cluster 3\n",
      "-------total data before removing node: [2141, 2071, 2053, 2097, 2101, 2085, 2107, 2062, 2131, 2089]\n",
      "Current the removing number of labels : [51, 44, 49, 44, 56, 40, 53, 46, 46, 44]\n",
      "-------total data after removing node : [2090, 2027, 2004, 2053, 2045, 2045, 2054, 2016, 2085, 2045]\n",
      "\n",
      "\n",
      "---------------- Round 19 ---------------\n",
      "add the node 134 to the cluster 9\n",
      "Remove the node 134 from G_r\n",
      "-------total data before removing node: [2090, 2027, 2004, 2053, 2045, 2045, 2054, 2016, 2085, 2045]\n",
      "Current the adding number of labels : [51, 44, 49, 44, 56, 40, 53, 46, 46, 44]\n",
      "-------total data after removing node : [2141, 2071, 2053, 2097, 2101, 2085, 2107, 2062, 2131, 2089]\n",
      "\n",
      "\n",
      "---------------- Round 20 ---------------\n",
      "Remove node 83 form the cluster 0\n",
      "-------total data before removing node: [2141, 2071, 2053, 2097, 2101, 2085, 2107, 2062, 2131, 2089]\n",
      "Current the removing number of labels : [43, 45, 37, 51, 39, 45, 43, 48, 44, 48]\n",
      "-------total data after removing node : [2098, 2026, 2016, 2046, 2062, 2040, 2064, 2014, 2087, 2041]\n",
      "-------- Complete adjustment --------\n"
     ]
    }
   ],
   "source": [
    "# --------- Step2. Data balancing for each cluster ------------\n",
    "\n",
    "max_id, min_id, sat_dc = find_max_min_c()\n",
    "print(\"--------- Step2. Data balancing for each cluster ------------\")\n",
    "#  adjust cluster data\n",
    "round = 1\n",
    "while (not(sat_dc)):\n",
    "    \n",
    "    print('\\n')\n",
    "    print('---------------- Round {} ---------------'.format(round))\n",
    "    round+=1\n",
    "    \n",
    "    \n",
    "    # find the leaf nodes that removed its still satisfies data coverage\n",
    "    dc_leaf = find_cd_leaf_node(clusters[max_id])\n",
    "    \n",
    "    \n",
    "    # remove the leaf node from the max_cluster\n",
    "    if (len(dc_leaf) != 0):\n",
    "        max_s = find_max_cost_leaf(dc_leaf, max_id)     # the node has the highest cost in dc_leaf\n",
    "        \n",
    "        #remove max_s from max_cluster\n",
    "        clusters[max_id]['node'].remove(max_s)\n",
    "        clusters[max_id]['graph'].remove_node(max_s)\n",
    "        \n",
    "        # update the cluster trust\n",
    "        nodes = clusters[max_id]['node']\n",
    "        min_trust = 1 \n",
    "        for i in nodes:\n",
    "            for j in nodes:\n",
    "                if (get_2SIoT_trust(i,j)<min_trust):\n",
    "                    min_trust = get_2SIoT_trust(i,j)\n",
    "        clusters[max_id]['p_level'] = min_trust\n",
    "        \n",
    "        # update the hired_SIoTs\n",
    "        hired_SIoTs.remove(max_s)\n",
    "        \n",
    "        #reconstruct G_r\n",
    "        G_r = nx.Graph(G_s)\n",
    "        G_r.remove_nodes_from(list(hired_SIoTs))\n",
    "        print ('Remove node {} form the cluster {}'.format(max_s, max_id ))\n",
    "                              \n",
    "        # update the total_num_data\n",
    "        print (\"-------total data before removing node:\", total_num_data)\n",
    "        lc = [total_num_data[i]-G_s.nodes[max_s]['d_data'][i] for i in range(0, label)]\n",
    "        total_num_data = lc\n",
    "        print (\"Current the removing number of labels :\",G_s.nodes[max_s]['d_data'])\n",
    "        print (\"-------total data after removing node :\", total_num_data)\n",
    "                              \n",
    "                              \n",
    "    # insert the highest CP node to the min_cluster\n",
    "    else:\n",
    "        maxCP_s = find_highCP_s(clusters[min_id])\n",
    "        cluster_id = maxCP_s['cluster_id']\n",
    "        node_id = maxCP_s['node_id']\n",
    "        \n",
    "        # update the cluster info\n",
    "        print(\"add the node {} to the cluster {}\".format(node_id, cluster_id))       \n",
    "        clusters[cluster_id]['node'].append(node_id)\n",
    "        clusters[cluster_id]['p_level'] = maxCP_s['min_trust']\n",
    "        clusters[cluster_id]['graph'].add_nodes_from([(node_id, G_s.nodes[node_id] )])\n",
    "        clusters[cluster_id]['graph'].add_edges_from([(node_id, maxCP_s['nbr_min_c'], G_s[node_id][maxCP_s['nbr_min_c']])])\n",
    "        hired_SIoTs.add(node_id)\n",
    "                              \n",
    "        print (\"Remove the node {} from G_r\".format(node_id))\n",
    "        G_r.remove_node(node_id)\n",
    "                              \n",
    "        # update the total_num_data\n",
    "        print(\"-------total data before removing node:\", total_num_data)\n",
    "        lc = [total_num_data[i]+G_s.nodes[node_id]['d_data'][i] for i in range(0, label)]\n",
    "        total_num_data = lc\n",
    "        print(\"Current the adding number of labels :\",G_s.nodes[node_id]['d_data'])\n",
    "        print(\"-------total data after removing node :\", total_num_data)\n",
    "    \n",
    "    max_id, min_id, sat_dc = find_max_min_c()\n",
    "    \n",
    "print(\"-------- Complete adjustment --------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "favorite-manchester",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set node 133 as the cluster head of the cluster 0\n",
      "set node 120 as the cluster head of the cluster 1\n",
      "set node 178 as the cluster head of the cluster 2\n",
      "set node 90 as the cluster head of the cluster 3\n",
      "set node 168 as the cluster head of the cluster 4\n",
      "set node 149 as the cluster head of the cluster 5\n",
      "set node 138 as the cluster head of the cluster 6\n",
      "set node 176 as the cluster head of the cluster 7\n",
      "set node 22 as the cluster head of the cluster 8\n",
      "set node 177 as the cluster head of the cluster 9\n",
      "\n",
      "\n",
      "start rerouting the cluster 0\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "                Complete Rerouting                \n",
      "-------- Total reducing cost: 0 --------\n",
      "\n",
      "\n",
      "start rerouting the cluster 1\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "                Complete Rerouting                \n",
      "-------- Total reducing cost: 0 --------\n",
      "\n",
      "\n",
      "start rerouting the cluster 2\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "                Complete Rerouting                \n",
      "-------- Total reducing cost: 0 --------\n",
      "\n",
      "\n",
      "start rerouting the cluster 3\n",
      "-------------------------------------------------\n",
      "change (41, 13) to (41, 15)\n",
      "reduce the total cost : 3.0\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "                Complete Rerouting                \n",
      "-------- Total reducing cost: 3.0 --------\n",
      "\n",
      "\n",
      "start rerouting the cluster 4\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "                Complete Rerouting                \n",
      "-------- Total reducing cost: 0 --------\n",
      "\n",
      "\n",
      "start rerouting the cluster 5\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "                Complete Rerouting                \n",
      "-------- Total reducing cost: 0 --------\n",
      "\n",
      "\n",
      "start rerouting the cluster 6\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "                Complete Rerouting                \n",
      "-------- Total reducing cost: 0 --------\n",
      "\n",
      "\n",
      "start rerouting the cluster 7\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "                Complete Rerouting                \n",
      "-------- Total reducing cost: 0 --------\n",
      "\n",
      "\n",
      "start rerouting the cluster 8\n",
      "-------------------------------------------------\n",
      "change (172, 93) to (172, 22)\n",
      "reduce the total cost : 7.599999999999994\n",
      "-------------------------------------------------\n",
      "change (103, 118) to (103, 22)\n",
      "reduce the total cost : 3.0\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "                Complete Rerouting                \n",
      "-------- Total reducing cost: 10.599999999999994 --------\n",
      "\n",
      "\n",
      "start rerouting the cluster 9\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "                Complete Rerouting                \n",
      "-------- Total reducing cost: 0 --------\n",
      "total number of hiring SIoT: 53\n",
      "[259, 247, 204.94000000000003, 453.1, 1164.04]\n"
     ]
    }
   ],
   "source": [
    "# --------- Step 3. Cluster head(CH) decision and Rerouting ------------\n",
    "\n",
    "# cluster head selection \n",
    "for c in clusters:\n",
    "    \n",
    "    c_ch =set() # the set of candidate cluster head\n",
    "    \n",
    "    # remove the leaf node from CH candidates\n",
    "    c_ch = set(c['node']) - set(find_leaf_node(c))\n",
    "    \n",
    "    # get the node with minimum total cost in the cluster c\n",
    "    ch = get_ch(c_ch, c)\n",
    "#     print(ch)\n",
    "    \n",
    "    # set the node ch as the cluster head in the cluster c\n",
    "    set_ch(ch,c)\n",
    "    print (\"set node {} as the cluster head of the cluster {}\".format(ch,c[\"id\"]))\n",
    "\n",
    "    \n",
    "# Rerouting\n",
    "for c in clusters:\n",
    "    print('\\n')\n",
    "    print(\"start rerouting the cluster {}\". format(c['id']))\n",
    "    print(\"-------------------------------------------------\")\n",
    "    routing = True\n",
    "    total_redu = 0\n",
    "    while (routing):\n",
    "        \n",
    "        # return the rerouting edge and \n",
    "        ori_e, rerout_e, routing = rerouting(c)\n",
    "        \n",
    "        if(routing): \n",
    "            \n",
    "            # change the ori. edge to the rerouting edge\n",
    "            change_route(ori_e, rerout_e, c['id'] )\n",
    "            \n",
    "            # update the cluster info.\n",
    "            redu_cost = update_c_info(c['id'])\n",
    "            total_redu += redu_cost\n",
    "            print('reduce the total cost :', redu_cost)\n",
    "        print(\"-------------------------------------------------\")\n",
    "    print ('                Complete Rerouting                ')\n",
    "    print ('-------- Total reducing cost: {} --------'.format(total_redu))\n",
    "    \n",
    "print(\"total number of hiring SIoT:\", len(hired_SIoTs))\n",
    "print(get_overall_cost())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "impressed-consumer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 0,\n",
       "  'graph': <networkx.classes.graph.Graph at 0x7f2245e7e290>,\n",
       "  'node': [133, 165, 148, 73, 60],\n",
       "  'p_level': 0.65,\n",
       "  'CH': 133,\n",
       "  'total_cmp': 20,\n",
       "  'total_cmu': 17,\n",
       "  'total_hir': 21.85,\n",
       "  'total_pri': 41.7,\n",
       "  'total_cst': 100.55000000000001},\n",
       " {'id': 1,\n",
       "  'graph': <networkx.classes.graph.Graph at 0x7f2245d8f3d0>,\n",
       "  'node': [120, 131, 186, 153],\n",
       "  'p_level': 0.45,\n",
       "  'CH': 120,\n",
       "  'total_cmp': 15,\n",
       "  'total_cmu': 15,\n",
       "  'total_hir': 19.33,\n",
       "  'total_pri': 42.88,\n",
       "  'total_cst': 92.21000000000001},\n",
       " {'id': 2,\n",
       "  'graph': <networkx.classes.graph.Graph at 0x7f2245d8f050>,\n",
       "  'node': [150, 178, 141, 18, 95],\n",
       "  'p_level': 0.45,\n",
       "  'CH': 178,\n",
       "  'total_cmp': 25,\n",
       "  'total_cmu': 17,\n",
       "  'total_hir': 18.59,\n",
       "  'total_pri': 53.6,\n",
       "  'total_cst': 114.19},\n",
       " {'id': 3,\n",
       "  'graph': <networkx.classes.graph.Graph at 0x7f2245d8f210>,\n",
       "  'node': [99, 13, 15, 41, 90, 140],\n",
       "  'p_level': 0.93,\n",
       "  'CH': 90,\n",
       "  'total_cmp': 31,\n",
       "  'total_cmu': 30,\n",
       "  'total_hir': 21.57,\n",
       "  'total_pri': 38.16,\n",
       "  'total_cst': 120.72999999999999},\n",
       " {'id': 4,\n",
       "  'graph': <networkx.classes.graph.Graph at 0x7f2245d8f0d0>,\n",
       "  'node': [62, 168, 187, 162, 77],\n",
       "  'p_level': 0.95,\n",
       "  'CH': 168,\n",
       "  'total_cmp': 27,\n",
       "  'total_cmu': 14,\n",
       "  'total_hir': 18.11,\n",
       "  'total_pri': 31.2,\n",
       "  'total_cst': 90.31},\n",
       " {'id': 5,\n",
       "  'graph': <networkx.classes.graph.Graph at 0x7f2245d8f390>,\n",
       "  'node': [71, 149, 20, 121, 101],\n",
       "  'p_level': 0.45,\n",
       "  'CH': 149,\n",
       "  'total_cmp': 20,\n",
       "  'total_cmu': 28,\n",
       "  'total_hir': 19.1,\n",
       "  'total_pri': 53.6,\n",
       "  'total_cst': 120.69999999999999},\n",
       " {'id': 6,\n",
       "  'graph': <networkx.classes.graph.Graph at 0x7f2245ef5f90>,\n",
       "  'node': [76, 138, 156, 16, 54],\n",
       "  'p_level': 0.73,\n",
       "  'CH': 138,\n",
       "  'total_cmp': 28,\n",
       "  'total_cmu': 22,\n",
       "  'total_hir': 19.42,\n",
       "  'total_pri': 38.3,\n",
       "  'total_cst': 107.72},\n",
       " {'id': 7,\n",
       "  'graph': <networkx.classes.graph.Graph at 0x7f2245d41410>,\n",
       "  'node': [50, 55, 63, 176, 27, 145, 14],\n",
       "  'p_level': 0.73,\n",
       "  'CH': 176,\n",
       "  'total_cmp': 31,\n",
       "  'total_cmu': 45,\n",
       "  'total_hir': 24.63,\n",
       "  'total_pri': 53.62,\n",
       "  'total_cst': 154.25},\n",
       " {'id': 8,\n",
       "  'graph': <networkx.classes.graph.Graph at 0x7f2245d8f890>,\n",
       "  'node': [103, 118, 22, 93, 172],\n",
       "  'p_level': 0.5,\n",
       "  'CH': 22,\n",
       "  'total_cmp': 29,\n",
       "  'total_cmu': 22,\n",
       "  'total_hir': 20.13,\n",
       "  'total_pri': 50.0,\n",
       "  'total_cst': 121.13},\n",
       " {'id': 9,\n",
       "  'graph': <networkx.classes.graph.Graph at 0x7f22461622d0>,\n",
       "  'node': [91, 194, 166, 177, 65, 134],\n",
       "  'p_level': 0.65,\n",
       "  'CH': 177,\n",
       "  'total_cmp': 33,\n",
       "  'total_cmu': 37,\n",
       "  'total_hir': 22.21,\n",
       "  'total_pri': 50.04,\n",
       "  'total_cst': 142.25}]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "killing-sigma",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "homeless-british",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Py3.7.9",
   "language": "python",
   "name": "dshw1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
